{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a787eb-46b3-429f-909c-41301f779899",
   "metadata": {},
   "source": [
    "# Screening tool for employers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189bc11-b66b-46da-ba8e-a204c48090d1",
   "metadata": {},
   "source": [
    "Hello, Employer are you having problems getting through all the candidates that are applying for your graduate positions?\n",
    "Well we have the solution for You!\n",
    "This product will allow you to score personal statements before getting to the interview stage to save time on meeting applicants that do not meet the minimum requirements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe5a0c-efd5-420c-880e-9a53f1002094",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf44d8e0-3939-45f6-aeeb-54713d6042c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tritonclient.http as httpclient\n",
    "import riva.client\n",
    "import wave\n",
    "import IPython\n",
    "\n",
    "from tritonclient.utils import np_to_triton_dtype\n",
    "\n",
    "auth = riva.client.Auth(uri='10.100.182.246:50051')\n",
    "tts_service = riva.client.SpeechSynthesisService(auth)\n",
    "\n",
    "URL = \"10.98.96.143:8000\"\n",
    "MODEl_GPTJ_FASTERTRANSFORMER = \"ensemble\" \n",
    "\n",
    "OUTPUT_LEN = 128\n",
    "BATCH_SIZE = 1\n",
    "BEAM_WIDTH = 2\n",
    "TOP_K = 1\n",
    "TOP_P = 0.0\n",
    "\n",
    "start_id = 220\n",
    "end_id = 50256\n",
    "\n",
    "client = httpclient.InferenceServerClient(URL,\n",
    "                                           concurrency=1,\n",
    "                                           verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0fcc4c-4a2b-42a9-8590-fe0505c6dbc2",
   "metadata": {},
   "source": [
    "## Personal statement summary tools \n",
    "These functions will summararise the personal statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c767dc6c-62be-42fe-a7d6-025a28275807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference hyperparameters\n",
    "def prepare_tensor(name, input):\n",
    "    tensor = httpclient.InferInput(\n",
    "        name, input.shape, np_to_triton_dtype(input.dtype))\n",
    "    tensor.set_data_from_numpy(input)\n",
    "    return tensor\n",
    "\n",
    "# explanation\n",
    "def prepare_inputs(input0):\n",
    "    bad_words_list = np.array([[\"\"]], dtype=object)\n",
    "    stop_words_list = np.array([[\"\"]], dtype=object)\n",
    "    input0_data = np.array(input0).astype(object)\n",
    "    output0_len = np.ones_like(input0).astype(np.uint32) * OUTPUT_LEN\n",
    "    runtime_top_k = (TOP_K * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    runtime_top_p = TOP_P * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    beam_search_diversity_rate = 0.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    temperature = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    len_penalty = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    repetition_penalty = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    random_seed = 0 * np.ones([input0_data.shape[0], 1]).astype(np.int32)\n",
    "    is_return_log_probs = True * np.ones([input0_data.shape[0], 1]).astype(bool)\n",
    "    beam_width = (BEAM_WIDTH * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    start_ids = start_id * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "    end_ids = end_id * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "\n",
    "    inputs = [\n",
    "        prepare_tensor(\"INPUT_0\", input0_data),\n",
    "        prepare_tensor(\"INPUT_1\", output0_len),\n",
    "        prepare_tensor(\"INPUT_2\", bad_words_list),\n",
    "        prepare_tensor(\"INPUT_3\", stop_words_list),\n",
    "        prepare_tensor(\"runtime_top_k\", runtime_top_k),\n",
    "        prepare_tensor(\"runtime_top_p\", runtime_top_p),\n",
    "        prepare_tensor(\"beam_search_diversity_rate\", beam_search_diversity_rate),\n",
    "        prepare_tensor(\"temperature\", temperature),\n",
    "        prepare_tensor(\"len_penalty\", len_penalty),\n",
    "        prepare_tensor(\"repetition_penalty\", repetition_penalty),\n",
    "        prepare_tensor(\"random_seed\", random_seed),\n",
    "        prepare_tensor(\"is_return_log_probs\", is_return_log_probs),\n",
    "        prepare_tensor(\"beam_width\", beam_width),\n",
    "        prepare_tensor(\"start_id\", start_ids),\n",
    "        prepare_tensor(\"end_id\", end_ids),\n",
    "    ]\n",
    "    return inputs\n",
    "good_words = ['computer']\n",
    "bad_words = ['science']\n",
    "\n",
    "#long input is a list of paragraphs\n",
    "def statement_scoring(long_input, good_words, bad_words):\n",
    "    score = 0\n",
    "    for paragraph in longer_inputs:\n",
    "        words = paragraph.lower().split(\" \")\n",
    "        for i in words:\n",
    "            if i in good_words:\n",
    "                score += 1\n",
    "            if i in bad_words:\n",
    "                score -= 1\n",
    "    return score\n",
    "def convert(s):\n",
    "    # initialization of string to \"\"\n",
    "    new = \"\"\n",
    "    # traverse in the string\n",
    "    for x in s:\n",
    "        new += x\n",
    "    # return string\n",
    "    return [new]\n",
    "\n",
    "def summerisation_preporcessing(personal_statement_path):\n",
    "    f = open(personal_statement_path, \"r\")\n",
    "    longer_inputs = []\n",
    "    for x in f:\n",
    "        longer_inputs.append(x)\n",
    "    temp = [\"\"]\n",
    "    for i in longer_inputs:\n",
    "        if i != '\\n':\n",
    "            temp += i\n",
    "    temp2 = convert(temp)\n",
    "    temp2.append('\\n\\ntl;dr:\\n')\n",
    "    return longer_inputs, temp2\n",
    "\n",
    "def summary(text_to_summerise):\n",
    "    input0 = [[text_to_summerise[0] + text_to_summerise[1]],]\n",
    "    inputs = prepare_inputs(input0)\n",
    "    result = client.infer(MODEl_GPTJ_FASTERTRANSFORMER, inputs)\n",
    "    output0 = result.as_numpy(\"OUTPUT_0\")\n",
    "    return output0[0].decode('UTF-8').replace('<|endoftext|>', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec18c0-2529-4b8e-8eef-72d409772f67",
   "metadata": {},
   "source": [
    "## Personal statement rating tools\n",
    "We will rate the personal statement using key words and a profanity filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083805e8-3b6e-4c4e-96c8-58417c2d7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#long input is a list of paragraphs\n",
    "def statement_scoring(long_input, good_words, bad_words):\n",
    "    score = 0\n",
    "    for paragraph in longer_inputs:\n",
    "        words = paragraph.lower().split(\" \")\n",
    "        for i in words:\n",
    "            if i in good_words:\n",
    "                score += 1\n",
    "            if i in bad_words:\n",
    "                score -= 1\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f50a2-29ce-494e-bec2-65d164fbb88c",
   "metadata": {},
   "source": [
    "### Full personal statement analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60f44ec-b8ea-4680-929f-29fb67009e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_summerisation(personal_statement_path, good_words, bad_words):\n",
    "    longer_inputs, temp2 = summerisation_preporcessing(personal_statement_path)\n",
    "    summary_text = summary(temp2)\n",
    "    score = statement_scoring(longer_inputs, good_words, bad_words)\n",
    "    return score, summary_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15951a-0d17-4048-8539-34ee2c7313e0",
   "metadata": {},
   "source": [
    "## Interview Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2e6a2-ad87-493a-8c70-adffc3b08f06",
   "metadata": {},
   "source": [
    "### Audio transcription\n",
    "These functions are used to transcribe audio data from the interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617364a7-7c59-4ead-a770-450663be3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scribe_audio(my_wav_file):\n",
    "    asr_service = riva.client.ASRService(auth)\n",
    "\n",
    "    offline_config = riva.client.RecognitionConfig(\n",
    "        encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "        max_alternatives=1,\n",
    "        enable_automatic_punctuation=True,\n",
    "        verbatim_transcripts=False,\n",
    "    )\n",
    "    \n",
    "    riva.client.add_audio_file_specs_to_config(offline_config, my_wav_file)\n",
    "    \n",
    "    # BOOSTING\n",
    "    # Add words that aren't scribed properly\n",
    "    boosted_lm_words = ['word1','hello','name','UAV','CEZ','CDNN']\n",
    "    boosted_lm_score = 20.0\n",
    "    riva.client.add_word_boosting_to_config(offline_config, boosted_lm_words, boosted_lm_score)\n",
    "    riva.client.add_audio_file_specs_to_config(offline_config, my_wav_file)\n",
    "    \n",
    "    with open(my_wav_file, 'rb') as fh:\n",
    "        data = fh.read()\n",
    "    \n",
    "    response = asr_service.offline_recognize(data, offline_config)\n",
    "    response = '%s' %response\n",
    "    k =  response.find('transcript')\n",
    "    m = len(\"transcript:\")+2\n",
    "    k2 = response.find('\\n',k)\n",
    "    string_response = response[k+m:k2-1]\n",
    "    return string_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca24086-6ebe-4302-9101-8827cde7d90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc41ace-46dc-4757-adeb-f4e4834658b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1702c31-b1cd-451f-973e-c20197570935",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9ab105-66c4-4b3c-924f-16d3aea6c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_statement_and_interview(path_to_statement, path_to_audio_dir, name):\n",
    "#     Takes the path to a directory containing all appropriate audio files\n",
    "#     Take path to personal statement\n",
    "#     Returns a file containing a summarisation of the personal statement and the audio file\n",
    "#     filename will be the name of the inverviewe and the score of their personal statement\n",
    "    # Rate and summarise personal statement, note: the good_word and bad_words are just a \n",
    "    # stand-in for more complex ratings\n",
    "    good_words = ['computer']\n",
    "    bad_words = ['pay raise']\n",
    "    statement_score, statement_summary = complete_summerisation(path_to_statement, good_words, bad_words)    \n",
    "    # transcribe inverview\n",
    "    interview_questions = [\"1. Hello, Please describe yousrelf in 4 or less sentences\",\n",
    "                           \"2. What is your previous work experience\",\n",
    "                           \"3. How will you contribute to our team\",\n",
    "                           \"4. Where do you see yourself in 5 years\",\n",
    "                           \"5. What do you do on the weekend?\",\n",
    "                           \"6. Do you have any questions for us?\"]\n",
    "    interview_answers = []\n",
    "    file_names = os.listdir(path_to_audio_dir)\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(path_to_audio_dir, file_name)\n",
    "        interview_answers.append(scribe_audio(file_path))\n",
    "    \n",
    "    # Add all data to output file\n",
    "    with open(f\"{name}_{statement_score}_EN.txt\", \"r\") as f:\n",
    "        f.write(\"PERSONAL STATEMENT SUMMARY\\n\\n\")\n",
    "        f.write(statement_summary)\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"INTERVIEW TRANSCRIPT\\n\\n\")\n",
    "        for id in range(len(interview_answers)):\n",
    "            f.write(interview_questions[id])\n",
    "            f.write(\"\\n\\t\")\n",
    "            f.write(interview_answers[id])\n",
    "            f.write(\"\\n\\n\")\n",
    "        \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6c24c6-b8c5-4fac-823a-969e9ab5b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarise_statement_and_interview(r\"./personal_statement.txt\", r\"./answer_audio\", \"Bob Ross\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f24dc-9f0c-4ebb-8952-599ee5d5de3b",
   "metadata": {},
   "source": [
    "# Note: OUR AUDIO INTERFACE\n",
    "We created a method for our user to record their interview question answers locally and then submit to our interviewing tool. This python script give susers a specified amount of time to answer and then stores it locally. The next step of this is to run a bash script which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdeb02e-8f7c-4678-9426-515cfa8d24ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
